{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "543b5826",
   "metadata": {},
   "source": [
    "# Load EEG Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c4a07a",
   "metadata": {},
   "source": [
    "## BCI2000\n",
    "\n",
    "### Experimental Protocol\n",
    "\n",
    "The data set consists of over 1500 one- and two-minute EEG recordings, obtained from 109 volunteers, as described below. The dataset was anonymized by the researchers.\n",
    "\n",
    "The original data is [here](https://physionet.org/content/eegmmidb/1.0.0/). \n",
    "\n",
    "It is licensed under the [Open Data Commons Attribution License v1.0](https://physionet.org/content/eegmmidb/view-license/1.0.0/)\n",
    "\n",
    "109 subjects performed different motor/imagery tasks while 64-channel EEG were recorded using the BCI2000 system (http://www.bci2000.org). Each subject performed 14 experimental runs: two one-minute baseline runs (one with eyes open, one with eyes closed), and three two-minute runs of each of the four following tasks:\n",
    "\n",
    "1. A target appears on either the left or the right side of the screen. The subject opens and closes the corresponding fist until the target disappears. Then the subject relaxes.\n",
    "2. A target appears on either the left or the right side of the screen. The subject imagines opening and closing the corresponding fist until the target disappears. Then the subject relaxes.\n",
    "3. A target appears on either the top or the bottom of the screen. The subject opens and closes either both fists (if the target is on top) or both feet (if the target is on the bottom) until the target disappears. Then the subject relaxes.\n",
    "4. A target appears on either the top or the bottom of the screen. The subject imagines opening and closing either both fists (if the target is on top) or both feet (if the target is on the bottom) until the target disappears. Then the subject relaxes.\n",
    "In summary, the experimental runs were:\n",
    "\n",
    "+ Baseline, eyes open\n",
    "+ Baseline, eyes closed\n",
    "+ Task 1 (open and close left or right fist)\n",
    "+ Task 2 (imagine opening and closing left or right fist)\n",
    "+ Task 3 (open and close both fists or both feet)\n",
    "+ Task 4 (imagine opening and closing both fists or both feet)\n",
    "+ Task 1\n",
    "+ Task 2\n",
    "+ Task 3\n",
    "+ Task 4\n",
    "+ Task 1\n",
    "+ Task 2\n",
    "+ Task 3\n",
    "+ Task 4\n",
    "\n",
    "The data are provided here in EDF+ format (containing 64 EEG signals, each sampled at 160 samples per second, and an annotation channel). For use with PhysioToolkit software, rdedfann generated a separate PhysioBank-compatible annotation file (with the suffix .event) for each recording. The .event files and the annotation channels in the corresponding .edf files contain identical data.\n",
    "\n",
    "Each annotation includes one of three codes (T0, T1, or T2):\n",
    "\n",
    "+ T0 corresponds to rest\n",
    "+ T1 corresponds to onset of motion (real or imagined) of the left fist (in runs 3, 4, 7, 8, 11, and 12) both fists (in runs 5, 6, 9, 10, 13, and 14)\n",
    "+ T2 corresponds to onset of motion (real or imagined) of the right fist (in runs 3, 4, 7, 8, 11, and 12) both feet (in runs 5, 6, 9, 10, 13, and 14)\n",
    "\n",
    "In the BCI2000-format versions of these files, which may be available from the contributors of this data set, these annotations are encoded as values of 0, 1, or 2 in the TargetCode state variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96158274",
   "metadata": {},
   "source": [
    "This data set was created and contributed to PhysioBank by Gerwin Schalk (schalk at wadsworth dot org) and his colleagues at the BCI R&D Program, Wadsworth Center, New York State Department of Health, Albany, NY. W.A. Sarnacki collected the data. Aditya Joshi compiled the dataset and prepared the documentation. D.J. McFarland and J.R. Wolpaw were responsible for experimental design and project oversight, respectively. This work was supported by grants from NIH/NIBIB ((EB006356 (GS) and EB00856 (JRW and GS)).\n",
    "\n",
    "The original publication can be found here:\n",
    "[Schalk, G., McFarland, D.J., Hinterberger, T., Birbaumer, N., Wolpaw, J.R. BCI2000: A General-Purpose Brain-Computer Interface (BCI) System. IEEE Transactions on Biomedical Engineering 51(6):1034-1043, 2004.](https://ieeexplore.ieee.org/document/1300799)\n",
    "\n",
    "The PhysioNet publication is here:\n",
    "[Goldberger, A., Amaral, L., Glass, L., Hausdorff, J., Ivanov, P. C., Mark, R., ... & Stanley, H. E. (2000). PhysioBank, PhysioToolkit, and PhysioNet: Components of a new research resource for complex physiologic signals. Circulation. 101 (23), pp. e215â€“e220.](https://pubmed.ncbi.nlm.nih.gov/10851218/)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d15d5755",
   "metadata": {},
   "source": [
    "# You can download and unzip the EEG dataset with this command.\n",
    "!wget -q --show-progress -O tmp.zip https://physionet.org/static/published-projects/eegmmidb/eeg-motor-movementimagery-dataset-1.0.0.zip && unzip -qq tmp.zip && rm tmp.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7be5bdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyedflib import highlevel\n",
    "\n",
    "import csv\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "#from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19a608f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [\"Baseline, eyes open\",\n",
    "         \"Baseline, eyes closed\",\n",
    "         \"Task 1\",\n",
    "         \"Task 2\",\n",
    "         \"Task 3\",\n",
    "         \"Task 4\",\n",
    "         \"Task 1\",\n",
    "         \"Task 2\",\n",
    "         \"Task 3\",\n",
    "         \"Task 4\",\n",
    "         \"Task 1\",\n",
    "         \"Task 2\",\n",
    "         \"Task 3\",\n",
    "         \"Task 4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f796dcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "490fa9ed843c4e70aeab60816767753b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1526 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "filenames = tqdm(glob.glob(\"./files/S*/*.edf\"), position=0)\n",
    "\n",
    "with open('eeg_data.csv', 'w', newline='') as csvfile:\n",
    "    datawriter = csv.writer(csvfile, quoting=csv.QUOTE_MINIMAL)\n",
    "    datawriter.writerow([\"Filename\", \"Task\", \"Run\", \"Code\", \"EEG\"])\n",
    "    \n",
    "    for filename in filenames:\n",
    "\n",
    "        filenames.set_description(f\"{filename}\")\n",
    "\n",
    "        run_idx = int(os.path.splitext(os.path.basename(filename))[0].split(\"R\")[1]) - 1\n",
    "        task = tasks[run_idx]\n",
    "\n",
    "        signals, signal_headers, header = highlevel.read_edf(filename)\n",
    "\n",
    "        sample_rate = signal_headers[0][\"sample_rate\"]\n",
    "\n",
    "        for idx in range(len(header[\"annotations\"])):\n",
    "\n",
    "            length_time = int(np.ceil(header[\"annotations\"][idx][1] * sample_rate)) \n",
    "            data = np.zeros((len(signals), length_time))\n",
    "\n",
    "            for channel in range(len(signals)):\n",
    "\n",
    "                begin_idx = int(header[\"annotations\"][idx][0] * sample_rate)\n",
    "                end_idx   = int((header[\"annotations\"][idx][0] + header[\"annotations\"][idx][1]) * sample_rate)\n",
    "\n",
    "                code_label = header[\"annotations\"][idx][2]\n",
    "                \n",
    "                eeg = signals[channel, begin_idx:end_idx]\n",
    "                eeg = (eeg - np.mean(eeg)) / np.std(eeg)\n",
    "\n",
    "                data[channel, :len(eeg)] = eeg\n",
    "            \n",
    "        datawriter.writerow([filename, task, run_idx, code_label, data])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470794ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
